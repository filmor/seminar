\documentclass[a4paper]{scrartcl}

\usepackage[ngerman]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[scale=0.8]{geometry}
\usepackage{amsmath}
\usepackage{units}

\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}

\DeclareMathSymbol{,}{\mathpunct}{letters}{"3B}
\DeclareMathSymbol{.}{\mathord}{letters}{"3B}
\DeclareMathSymbol{\decimal}{\mathord}{letters}{"3A}

\author{Benedikt Sauer}
\title{N-Körperproblem}

\begin{document}
\maketitle
\begin{abstract}
  Dieser Vortrag behandelt die Implementierung und Verwendung von
  N-Körpersimulationen zur Berechnung der Verteilung dunkler Materie im
  Universum, insbesondere die in GADGET-2 eingesetzte TreePM-Methode.
\end{abstract}
\section{Einführung}
Das Mehrkörperproblem besteht allgemein aus mehreren paarweise untereinander
wechselwirkenden Körper. Für den Fall von genau zwei Körpern (Keplerproblem) ist
es vollständig (und elementar) lösbar. Für mehr als zwei Körpern existiert zwar
eine analytische Lösung (\cite{wang}), diese ist allerdings mehr von
theoretischer Bedeutung. Hier wird die numerische Lösung betrachtet.

Die Hamiltonfunktion des Problems ist
\begin{align}
  \mathcal{H}(p_i, x_i) = \sum_i \frac{\left|p_i\right|}{2m_i} +
  \frac{1}{2} \sum_{i,j} m_i m_j \varphi(x_i - x_j)
  \label{eq:hamilton}
\end{align}
Das darin benötigte Potential erfüllt die Poissongleichung:
\begin{align}
  \Delta \varphi(x) = 4\pi G \rho(x)\text{, mit }\rho(x) = \sum_{i=1}^n m_i
  \delta_d(x - x_i)
  \label{eq:poisson}
\end{align}

Die Lösung selbiger ist das Hauptproblem der Simulationen (und das hier
behandelte). Der andere wichtige Bestandteil ist die Zeitentwicklung, auf die
Implementierung dieser wird zum Beispiel in \cite{gadget-zeit} oder
\cite{gadget-zeit2} näher eingegangen.

\section{Implementierung in Gadget}
Um die Poissongleichung zu lösen (bzw. konkret die Kraft auf ein Teilchen zu
berechnen) kann man verschiedene Methoden verwenden:
\begin{description}
  \item[PP-Methode (Particle-Particle)]
    Hierbei werden die Kräfte auf ein Teilchen explizit ausgerechnet, indem
    sämtliche Beiträge aller anderen aufaddiert werden. die Komplexität ist also
    quadratisch ($\mathcal O(n^2)$), was ein erheblicher Nachteil ist.
  \item[PM-Methode (Particle-Mesh)]
    Der Raum wird hierbei mit einem Gitter gefüllt. Für jeden einzelnen
    Gitterpunkt wird dann eine Dichte ausgerechnet. Anschließend wird dieses
    Gitter fouriertransformiert (konkret durch eine FFT), wodurch sich die
    partielle Differentialgleichung zu einer algebraischen Gleichung
    ($\left|\hat x\right| \hat \varphi(\hat x) = 4\pi G \hat \rho(\hat x)$)
    vereinfacht. Diese wird dann im transformierten Raum gelöst und wieder per
    FFT zurücktransformiert.  Die Methode hat ein deutlich besseres
    Laufzeitverhalten als PP ($\mathcal O(n\log n)$), unterschätzt aber auf
    geringe Distanzen zwangsläufig durch die endliche Gitterauflösung die
    Kräfte.
  \item[P³M-Methode (Particle-Particle - Particle-Mesh)]
    Bei dieser Methode werden die Vorteile der beiden Methoden vereint, indem
    die Kräfte nur in einem kleinen Radius um ein Teilchen herum direkt
    ausgerechnet werden und auf größere Distanzen die Particle-Mesh-Methode zum
    Einsatz kommt, die Linearität der Poissongleichung ausnutzend. Allerdings
    sieht man in Simulationen meistens ein Zusammenklumpen der Teilchen in Halos
    von relativ kleinem Radius, wodurch wieder das meiste mit der $\mathcal O
    (n^2)$-Methode berechnet wird.
\end{description}

Um den letztgenannten Nachteil gar nicht erst aufkommen zu lassen, wird im
GADGET2-Code (\cite{gadget}) die \emph{TreePM}-Methode, die einen
Baumalgorithmus statt der PP-Methode auf kurze Distanzen verwendet eingesetzt.
Der Raum wird dabei zunächst rekursiv in jeweils acht gleichgroße Würfel
aufgeteilt bis jeder Teilwürfel nur noch genau ein Teilchen enthält, das
Ergebnis wird in einem Octree gespeichert, dessen Blätter eben diese Würfel mit
nur noch einem Teilchen sind. In den anderen Knoten sind nur die Kindknoten
gespeichert, alle Daten liegen also in den Blättern.

Um nun die Kraft auf ein Teilchen auszurechnen wird der Baum rekursiv
durchlaufen, angefangen bei der Wurzel. Für jeden Knoten wird nun anhand
bestimmter Parameter (z.~B. bisherige Lauftiefe, Entfernung des Mittelpunkts des
aktuellen Würfels zum betrachteten Teilchen) bestimmt, ob noch weiter
abgestiegen wird oder die Genauigkeit nun ausreicht. Ist das der Fall, so wird
eine Multipolentwicklung durchgeführt, wobei es sich gezeigt hat, dass der erste
Term der Entwicklung, also schlicht die Summe der Massen (falls die Masse aller
Teilchen gleich ist und leere Würfel nicht gespeichert werden also die Anzahl
der Blätter des Teilbaums mal der Teilchenmasse) und damit die Kraft errechnet.

Genauigkeit und Geschwindigkeit hängen dabei stark von unserer Abbruchbedingung
ab (also wie tief wir durchschnittlich in den Baum hineinlaufen). Ist diese
anständig gewählt (bei GADGET etwa <+Wert aus Gadget+>\cite{gadget-abbruch}), so
erhält man eine Laufzeit von $\mathcal{O}(\log n)$ für den Baum, insgesamt also
$\mathcal O(n\log n)$ wie bei der PM-Methode. Die Gesamtlaufzeit ist also
ebenfalls $\mathcal O(n\log n)$.

\section{Ergebnisse}
\subsection{Milleniumssimulation}

\subsection{Project Aquarius}
Bei \emph{Project Aquarius} nahm man sich einen Halo aus einer anderen
Simulation, der von Größe und Gestalt dem entspricht, den man für die
Milchstraße annimmt und rechnete für diesen in höherer Auflösung weiter. Ein
wichtiges Ergebnis der Simulation war, dass die Zuordnung
Subcluster~$\leftrightarrow$~Satellitengalaxie so nicht zutreffen kann, da weit
mehr <+Größenordnung+> Subcluster entstehen als Satellitengalaxien zu beobachten
sind.

%\begin{thebibliography}
%    \begin{biblist}
%      bla
%    \end{biblist}
%\end{thebibliography}

\end{document}
